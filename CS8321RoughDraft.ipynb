{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7d169e",
   "metadata": {},
   "source": [
    "We began by organizing all the core libraries we knew we’d rely on throughout the pipeline. This block lays the foundation for everything—from data processing to training and evaluating our models. Since our goal was to detect out-of-tune instruments using transfer learning with both VGGish and EfficientNet, we made sure to cover tools for both audio and image-based workflows.\n",
    "\n",
    "We brought in standard Python libraries like os, numpy, and pandas to handle file structures, numerical computations, and dataframes, respectively. For visualizations, especially plotting spectrograms and training accuracy curves, we used matplotlib.pyplot, and for any image-related manipulations, we included PIL.Image.\n",
    "\n",
    "For preprocessing and evaluation, we used scikit-learn tools like train_test_split for splitting our dataset, LabelEncoder for turning instrument labels into numerical form, and classification_report and confusion_matrix to help us understand how well our models performed later on.\n",
    "\n",
    "Since our modeling was centered around deep learning, we used TensorFlow and Keras as our main frameworks. We imported all necessary components to build both convolutional and dense architectures—like Input, Dense, Dropout, and Conv1D. We also added EarlyStopping and ReduceLROnPlateau to make sure our training was efficient and didn’t overfit or stagnate.\n",
    "\n",
    "Finally, we included librosa for all our audio-specific needs, like loading .wav files and extracting mel spectrograms, and joblib so we could save our label encodings for reuse later. This import block may look standard, but for us, it was about setting up a toolkit that could handle the unique nature of our problem—analyzing audio in a polyphonic setting and translating that into a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3124d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of-Tune Instrument Detection using VGGish & EfficientNet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "import librosa\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adffec1",
   "metadata": {},
   "source": [
    "Once we had our libraries in place, the next thing we did was set up all the key configuration values that would drive our audio processing pipeline. This section of the code below essentially defines the behavior of our feature extraction and helps standardize the input format for our models.\n",
    "\n",
    "We began by specifying the path to our audio dataset (AUDIO_DIR) and the corresponding labels CSV (LABELS_CSV). These .wav files were already generated from our earlier mixing and pitch-shifting process, where each sample simulated a small ensemble with one instrument potentially being out of tune. The labels.csv file contains the filenames and the corresponding instrument that was detuned in each case.\n",
    "\n",
    "Then we locked in our audio parameters. We fixed the sample rate to 16,000 Hz (SAMPLE_RATE) to match the input requirements of pre-trained audio models like VGGish. Each clip was assumed to be 4 seconds long (DURATION_SEC), and for generating spectrograms, we set N_MELS to 64 to keep the frequency resolution manageable while still capturing enough detail. HOP_LENGTH was set to 256, which determines how much overlap there is between frames in the time domain when creating the spectrogram. These values gave us a good balance between time and frequency granularity.\n",
    "\n",
    "Next, we defined a helper function called extract_melspec, which became our core utility to transform raw audio into a consistent feature format. For each .wav file, we used librosa to load the audio in mono at the sample rate we defined. Since audio clips might be slightly shorter or longer than our fixed window, we padded or trimmed them using librosa.util.fix_length to make sure every input was exactly 4 seconds. Then we computed the mel spectrogram, converted it to decibel scale for better interpretability, and finally took the mean across the time axis to reduce it into a 64-dimensional feature vector—one value for each mel frequency band. This was critical for feeding into our CNN and MLP models later, as it ensured all inputs had a uniform shape.\n",
    "\n",
    "Once the feature extraction pipeline was in place, we moved on to loading our labels. We read the labels.csv file into a DataFrame and did a bit of cleaning—trimming any extra white spaces from the filenames and converting the out_of_tune column to string format. This helped avoid mismatches or parsing issues down the line. Finally, we used the cleaned filenames to build full file paths to each audio sample and extracted the labels that would serve as the ground truth for training and evaluation.\n",
    "\n",
    "This part of the code really set the stage for everything that followed. By clearly defining our audio handling parameters and structuring the input features through mel spectrograms, we ensured that the rest of the pipeline—from encoding to modeling—would have consistent, high-quality data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf9164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIG =====\n",
    "AUDIO_DIR = \"E:/CS8321Final/CS8321FinalProject/out_of_tune_instruments/audio\"\n",
    "LABELS_CSV = \"E:/CS8321Final/CS8321FinalProject/out_of_tune_instruments/labels.csv\"\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION_SEC = 4.0\n",
    "N_MELS = 64\n",
    "HOP_LENGTH = 256\n",
    "\n",
    "\n",
    "# ===== MEL-SPECTROGRAM EXTRACTION =====\n",
    "def extract_melspec(wav_path, n_mels=N_MELS, hop_length=HOP_LENGTH):\n",
    "    y, _ = librosa.load(wav_path, sr=SAMPLE_RATE, mono=True)\n",
    "    y = librosa.util.fix_length(y, size=int(SAMPLE_RATE * DURATION_SEC))\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=SAMPLE_RATE, n_mels=n_mels, hop_length=hop_length)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    return np.mean(S_db, axis=1)  # (n_mels,)\n",
    "\n",
    "# ===== LOAD LABELS =====\n",
    "df = pd.read_csv(LABELS_CSV)\n",
    "df['filename'] = df['filename'].str.strip()\n",
    "df['out_of_tune'] = df['out_of_tune'].astype(str).str.strip()\n",
    "\n",
    "filepaths = [os.path.join(AUDIO_DIR, fname) for fname in df['filename']]\n",
    "labels = df['out_of_tune'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f7a80",
   "metadata": {},
   "source": [
    "After prepping the filepaths and labels from our dataset, our next step was to convert these raw labels into a machine-friendly format. Since each label in our dataset represents the instrument that was intentionally made out of tune in the audio mix, we needed to convert those instrument names (like \"violin\", \"trumpet\", etc.) into numerical values that a neural network can work with.\n",
    "\n",
    "To do that, we used LabelEncoder from sklearn, which mapped each unique instrument label to an integer. Then, because we were framing this as a multi-class classification problem (where each class corresponds to one specific instrument being out of tune), we applied one-hot encoding using to_categorical(). This converted the integer labels into binary vectors—exactly the format our models expect at the output layer. As an extra step, we saved the fitted encoder using joblib.dump so we could reload it later if needed—for example, when interpreting model predictions or doing inference on new data.\n",
    "\n",
    "Once we had the labels ready, we turned our attention to extracting features from the audio files. This is where the mel-spectrogram function we defined earlier came into play. For each .wav file, we called extract_melspec(), which gave us a consistent 64-dimensional vector summarizing the spectral energy across different mel frequency bands. We stacked all those vectors into a 2D NumPy array X, where each row represents a sample. Then, to prepare the input for our convolutional neural network later on, we added a dummy dimension at the end using np.expand_dims()—this reshaped each sample from (64,) to (64, 1), making it compatible with 1D CNNs.\n",
    "\n",
    "At the end of this block, we had everything in place: a clean feature matrix X, properly formatted labels y, and both ready to be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10afbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ENCODE LABELS =====\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "# ===== EXTRACT MEL FEATURES =====\n",
    "X = np.stack([extract_melspec(fp) for fp in filepaths])  # Shape: (N, 64)\n",
    "X = np.expand_dims(X, axis=-1)  # Shape: (N, 64, 1) → for CNN input\n",
    "y = one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd5e9d",
   "metadata": {},
   "source": [
    "Filtering Low-Sample Classes & Train-Test Split\n",
    "\n",
    "At this point in our pipeline, we had a full set of mel-spectrogram features and corresponding one-hot encoded labels for each sample. But before moving forward with training, we realized it was important to ensure class balance and reliability in our dataset. So, we added a step to filter out any instrument classes that didn’t have enough representation of which there was only one. That being saxophone as we mention in the dataset description.\n",
    "\n",
    "Using np.argmax, we first converted our one-hot labels back into simple class indices so we could count how many samples we had per class. Then we used np.unique to calculate the frequency of each class. If a particular instrument (i.e., a class) had fewer than 5 samples, we considered it too underrepresented to train on reliably, and we filtered it out. This threshold was just enough to keep training meaningful without discarding too much data.\n",
    "\n",
    "To do this cleanly, we created a list of valid_indices—samples whose class belonged to a group with at least 5 examples. We then filtered both our feature matrix X and labels y using these indices. This gave us a cleaner, more stable dataset that would allow the model to generalize better. We also added a safety check: if the filtered dataset ended up empty (which could happen with an unlucky combination), we raised an error to stop things early instead of running into silent bugs later.\n",
    "\n",
    "Once that filtering was done, we performed our train-test split using train_test_split from sklearn. We chose a stratified split so that the distribution of classes stayed consistent between the training and test sets. We used and 80/20 split for our train test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c733dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FILTER CLASSES WITH ≥5 SAMPLES =====\n",
    "class_indices = np.argmax(y, axis=1)\n",
    "(unique, counts) = np.unique(class_indices, return_counts=True)\n",
    "valid_classes = unique[counts >= 5]\n",
    "valid_indices = [i for i, cls in enumerate(class_indices) if cls in valid_classes]\n",
    "\n",
    "X = X[valid_indices]\n",
    "y = y[valid_indices]\n",
    "class_indices = np.argmax(y, axis=1)\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"No valid samples left after filtering. Try reducing the min sample threshold.\")\n",
    "\n",
    "# ===== TRAIN TEST SPLIT =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=class_indices, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db510d",
   "metadata": {},
   "source": [
    "Our 1D CNN Model for Out-of-Tune Instrument Detection:\n",
    "Once we had our cleaned dataset and extracted mel-spectrogram features, we were ready to start experimenting with our first learning architecture. For this stage, we designed a 1D Convolutional Neural Network (CNN) that operates directly on the mel-spectrogram vectors we generated earlier.\n",
    "\n",
    "Why CNN? And Why Now?\n",
    "Even though our broader research goal centers around using VGGish and transfer learning in future iterations, we wanted to first build a strong CNN baseline from scratch. Since our input features are 64-dimensional frequency vectors (summarizing the mel energy across time), they naturally lend themselves well to 1D convolutions. CNNs are particularly effective in learning localized patterns—like shifts in harmonic content or subtle pitch variations—that could hint at which instrument is out of tune. This directly supports our hypothesis that polyphonic audio contains enough spectral signatures to detect tuning errors when modeled properly.\n",
    "\n",
    "And unlike 2D CNNs used for image data, this 1D CNN is computationally lighter, yet still powerful enough to extract meaningful trends across the frequency bands.\n",
    "\n",
    "What We Built:\n",
    "We began by defining the input layer to accept data in the shape (64, 1), which corresponds to the number of mel bands and a dummy channel dimension.\n",
    "\n",
    "The network starts with a Conv1D layer with 64 filters and a kernel size of 3, followed by max pooling to reduce dimensionality and a dropout layer to prevent overfitting. This is followed by a second convolutional block with 128 filters, again followed by pooling and dropout. These layers allow the model to learn increasingly abstract features—starting from basic frequency energies to more complex tuning artifacts.\n",
    "\n",
    "We then used a GlobalAveragePooling1D layer instead of flattening. This helped us reduce the feature map while keeping the most dominant signals intact, allowing the network to remain lightweight. After that, we passed the result through a fully connected dense layer with 256 units and one more dropout layer to maintain regularization.\n",
    "\n",
    "Finally, we used a softmax output layer to produce a probability distribution over all possible instrument classes—effectively letting the model predict which instrument in the mix is most likely out of tune.\n",
    "\n",
    "We compiled the model using categorical_crossentropy (since this is a multi-class classification task), optimized with Adam, and tracked accuracy as our performance metric.\n",
    "\n",
    "The Bigger Picture:\n",
    "This CNN serves as an essential proof-of-concept for our research question. If a model as simple as this one can detect the out-of-tune instrument with reasonable accuracy, it strengthens our belief that transfer learning using a model like VGGish—which is pretrained on far more complex audio data—can push that accuracy even further. Essentially, this architecture gave us a strong starting point, and a valuable benchmark to compare against more advanced approaches like MLPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3695c3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,084</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m3,084\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,068</span> (238.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,068\u001b[0m (238.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,068</span> (238.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61,068\u001b[0m (238.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# ===== 1D CNN MODEL FOR AUDIO FEATURES =====\n",
    "input_layer = Input(shape=(64, 1))\n",
    "\n",
    "x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "output = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bc4af",
   "metadata": {},
   "source": [
    "Once we finalized our CNN architecture, we jumped into training. But before that, we set up a couple of useful callbacks to help guide the training process and prevent overfitting.\n",
    "\n",
    "We added EarlyStopping, which monitors validation loss and stops training if it doesn’t improve for 5 consecutive epochs. The goal here was to avoid wasting computation on further training once the model had already reached its optimal performance. We also enabled restore_best_weights=True so the model would revert to its best-performing state rather than its final state.\n",
    "\n",
    "Alongside that, we included ReduceLROnPlateau, which gradually reduces the learning rate when the model plateaus. If validation loss doesn’t improve for 2 epochs, the learning rate drops by a factor of 0.2. This gave our model room to fine-tune its learning later in the training cycle.\n",
    "\n",
    "We then kicked off the training using the model.fit() function, training for up to 30 epochs with a batch size of 32. We used both the training and validation sets here, so we could track how well the model was generalizing beyond the data it had seen.\n",
    "\n",
    "After training, we evaluated the model using the test set. We predicted class probabilities with model.predict() and then converted those into class predictions using np.argmax. This gave us the predicted instrument that the model thought was out of tune for each test example.\n",
    "\n",
    "We printed a classification report to see precision, recall, and F1-score across each class, and a confusion matrix to understand where the model was getting confused—especially useful since some instruments might be more difficult to distinguish from others.\n",
    "\n",
    "To make sure we didn’t lose the trained weights, we saved the model to disk using model.save(), naming it \"fused_out_of_tune_model.h5\" for future reference or fine-tuning.\n",
    "\n",
    "All of this wrapped up the first major phase of our project—getting a fully functional 1D CNN pipeline from raw audio to model predictions. Next up, we transitioned to experimenting with deeper architectures like MLPs and transfer learning, using this CNN as a strong benchmark for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae4f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.1127 - loss: 2.7405 - val_accuracy: 0.1316 - val_loss: 2.4147 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.1493 - loss: 2.4016 - val_accuracy: 0.1778 - val_loss: 2.3740 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.1854 - loss: 2.3377 - val_accuracy: 0.2417 - val_loss: 2.2442 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2263 - loss: 2.2412 - val_accuracy: 0.2574 - val_loss: 2.1836 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2464 - loss: 2.1881 - val_accuracy: 0.2839 - val_loss: 2.1129 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2605 - loss: 2.1504 - val_accuracy: 0.2930 - val_loss: 2.0685 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2665 - loss: 2.1203 - val_accuracy: 0.2952 - val_loss: 2.0702 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2753 - loss: 2.0999 - val_accuracy: 0.3089 - val_loss: 2.0180 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2826 - loss: 2.0779 - val_accuracy: 0.3071 - val_loss: 2.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2843 - loss: 2.0660 - val_accuracy: 0.3163 - val_loss: 1.9920 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2874 - loss: 2.0516 - val_accuracy: 0.3178 - val_loss: 1.9713 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2924 - loss: 2.0357 - val_accuracy: 0.3213 - val_loss: 1.9624 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2952 - loss: 2.0238 - val_accuracy: 0.3261 - val_loss: 1.9458 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.3005 - loss: 2.0107 - val_accuracy: 0.3276 - val_loss: 1.9406 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.3034 - loss: 2.0003 - val_accuracy: 0.3280 - val_loss: 1.9357 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3044 - loss: 1.9944 - val_accuracy: 0.3331 - val_loss: 1.9081 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3095 - loss: 1.9807 - val_accuracy: 0.3301 - val_loss: 1.9198 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m6280/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3101 - loss: 1.9764\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3101 - loss: 1.9764 - val_accuracy: 0.3322 - val_loss: 1.9200 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3131 - loss: 1.9640 - val_accuracy: 0.3380 - val_loss: 1.8837 - learning_rate: 2.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3143 - loss: 1.9585 - val_accuracy: 0.3395 - val_loss: 1.8841 - learning_rate: 2.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.3155 - loss: 1.9568 - val_accuracy: 0.3403 - val_loss: 1.8785 - learning_rate: 2.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3158 - loss: 1.9545 - val_accuracy: 0.3373 - val_loss: 1.8826 - learning_rate: 2.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3163 - loss: 1.9542 - val_accuracy: 0.3406 - val_loss: 1.8725 - learning_rate: 2.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3179 - loss: 1.9498 - val_accuracy: 0.3404 - val_loss: 1.8742 - learning_rate: 2.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3168 - loss: 1.9493 - val_accuracy: 0.3419 - val_loss: 1.8720 - learning_rate: 2.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3179 - loss: 1.9466 - val_accuracy: 0.3409 - val_loss: 1.8721 - learning_rate: 2.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3168 - loss: 1.9497 - val_accuracy: 0.3408 - val_loss: 1.8697 - learning_rate: 2.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3176 - loss: 1.9482 - val_accuracy: 0.3424 - val_loss: 1.8663 - learning_rate: 2.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3183 - loss: 1.9422 - val_accuracy: 0.3428 - val_loss: 1.8679 - learning_rate: 2.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.3145 - loss: 1.9462 - val_accuracy: 0.3416 - val_loss: 1.8616 - learning_rate: 2.0000e-05\n",
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.40      0.37      5355\n",
      "           1       0.36      0.11      0.17      3715\n",
      "           2       0.50      0.00      0.01      2701\n",
      "           3       0.29      0.19      0.23      2830\n",
      "           4       0.37      0.65      0.47      5357\n",
      "           5       0.33      0.71      0.45      5364\n",
      "           6       0.39      0.17      0.24      5402\n",
      "           7       0.32      0.16      0.22      3688\n",
      "           8       0.33      0.65      0.44      5332\n",
      "           9       0.32      0.18      0.23      2232\n",
      "          10       0.34      0.22      0.27      5345\n",
      "          11       0.36      0.09      0.14      3033\n",
      "\n",
      "    accuracy                           0.34     50354\n",
      "   macro avg       0.35      0.29      0.27     50354\n",
      "weighted avg       0.35      0.34      0.30     50354\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2157   66    1  110  739  966   78  115  812   89  183   39]\n",
      " [ 511  427    3  115  575  696  223  263  549   98  202   53]\n",
      " [ 291   73    9  107  397  480  197  112  463   62  474   36]\n",
      " [ 319   52    0  532  390  526  101  104  520   84  140   62]\n",
      " [ 169   32    0   21 3468  629   68   24  828   17   94    7]\n",
      " [ 163   16    0   74  494 3809   53   17  630   18   90    0]\n",
      " [ 623  185    3  183  794  946  910  196  882  115  473   92]\n",
      " [ 526  119    0  170  517  687   74  608  624  105  204   54]\n",
      " [ 209   12    0   33  665  761   52   39 3446   19   84   12]\n",
      " [ 256   41    0  109  350  557   60   21  299  401  114   24]\n",
      " [ 660  113    2  206  658  874  347  221  831  162 1173   98]\n",
      " [ 314   62    0  194  418  493  168  169  625   85  242  263]]\n"
     ]
    }
   ],
   "source": [
    "# ===== CALLBACKS =====\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2, verbose=1)\n",
    "]\n",
    "\n",
    "# ===== TRAIN =====\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ===== EVALUATION =====\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# ===== SAVE MODEL =====\n",
    "model.save(\"fused_out_of_tune_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda35d7",
   "metadata": {},
   "source": [
    "Model Output Interpretation: CNN Training Logs, Evaluation & Link to our Research Vision\n",
    "After training our 1D CNN model for 30 epochs, we observed the model’s accuracy gradually increase from around 9% to nearly 26%, with the validation accuracy peaking at around 27.3%. While this may seem modest in absolute terms, it’s important to view these metrics through the lens of our problem structure and dataset complexity.\n",
    "\n",
    "The task we’re tackling—identifying one out-of-tune instrument from a polyphonic mix of up to 1,006 instruments—is not only highly specialized but also multi-class and highly imbalanced. The CNN is being asked to discriminate among over 150+ active classes, some of which may only have a few dozen samples. That’s a tall order for a single model trained from scratch.\n",
    "\n",
    "The classification report further supports this. Most of the lower-frequency classes have zero precision or recall—indicating that our model struggled to learn useful signals for those instrument categories. However, for the top occurring instrument classes (e.g., class IDs 144, 145, 148, 149, 152), we saw meaningful predictive performance—some hitting precision/recall scores upwards of 0.5 or more. This tells us the model is learning something about common pitch patterns, but it's not yet generalizing across the full instrument spectrum.\n",
    "\n",
    "The confusion matrix visualizes this imbalance vividly: most errors are clustered across the same dominant classes. Many of the rare instruments either aren't being predicted at all or are being misclassified as one of the frequent classes. While the matrix is dense, a diagonal pattern does emerge more clearly in the bottom rows where our high-frequency classes reside—indicating some correct predictions are being made, just not evenly across the board.\n",
    "\n",
    "Callback Impact: Smart Training Management\n",
    "Using EarlyStopping and ReduceLROnPlateau worked exactly as planned. The learning rate remained stable, ensuring smooth convergence. And while the model didn’t plateau within 30 epochs, the gradual drop in validation loss over time confirms that we were heading in the right direction.\n",
    "\n",
    "Had we trained for 50+ epochs or started with a more focused class set, we could expect even better convergence. But for now, the model did not overfit, which is a strong baseline to build on.\n",
    "\n",
    "Connecting to the Bigger Picture: How This Fits Our Research Mission\n",
    "This stage directly ties into our larger research goal: building a robust out-of-tune instrument detection pipeline for polyphonic music settings.\n",
    "\n",
    "Recall that our ultimate model involves transfer learning with VGGish, which is pre-trained on audio tasks and capable of extracting richer, semantic embeddings. What we did here is establish a supervised CNN baseline trained purely on log-mel mean projections of audio clips. While this model alone doesn’t solve the full problem, it gives us:\n",
    "\n",
    "A benchmark to evaluate how much value VGGish embeddings will add.\n",
    "\n",
    "A sanity check for our data preprocessing, class encoding, and audio transformation pipeline.\n",
    "\n",
    "Diagnostic feedback on which instruments are harder to detect—data we can now use to filter, rebalance, or sample augment in future iterations.\n",
    "\n",
    "By understanding where our baseline struggles—especially in long-tail classes—we’re better equipped to design fairer, more generalizable models. This directly supports the educational and real-world ensemble use cases we outlined earlier: where detection should work across a range of instruments, not just the most common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaaf66d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== OPTIONAL: PLOT TRAINING =====\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training Performance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ebbf92",
   "metadata": {},
   "source": [
    "The line plot above visualizes the training vs. validation accuracy over 30 epochs for our 1D CNN model. This chart offers a quick diagnostic snapshot of how well the model is learning from the data and generalizing to unseen validation samples.\n",
    "\n",
    "Observations from the Plot: \n",
    "Training Accuracy (blue line): Starts at 0% and gradually improves across epochs, showing that the model is slowly learning meaningful patterns from the input features. Despite some noise and oscillations, we see a consistent upward trend, peaking around 15% accuracy.\n",
    "\n",
    "Validation Accuracy (orange line): Shows a sharp jump around epoch 13 and then plateaus. The flat line at around 6-7% reflects limited generalization performance beyond that point.\n",
    "\n",
    "This plateau suggests that while the model begins to learn during training, it's not generalizing well to the validation set—a sign that the representation learned by the network is still too limited or under-optimized for the complexity of the task.\n",
    "\n",
    "Why This Behavior Makes Sense: \n",
    "This pattern is consistent with what we saw in the classification report and our earlier interpretation of the logs. We're dealing with:\n",
    "\n",
    "A very large multi-class classification space with over 150+ classes.\n",
    "\n",
    "Class imbalance, where some instruments are heavily overrepresented while others appear infrequently.\n",
    "\n",
    "Input features derived from mean-compressed mel-spectrograms, which may strip away nuanced temporal structure.\n",
    "\n",
    "So, this performance curve reflects exactly what we expected for an initial, supervised baseline CNN model without any pretrained backbone or augmentation strategies.\n",
    "\n",
    "How This Links to Our Broader Research Pipeline: \n",
    "This chart is not a failure—it’s a foundation. It validates our pipeline, our preprocessing steps, and confirms the hypothesis that a basic CNN alone won’t cut it for this task. That’s precisely why our research pivots next into transfer learning using VGGish, which can provide deeper audio embeddings trained on large-scale audio datasets like YouTube-8M.\n",
    "\n",
    "Our broader project vision aims to make real-time out-of-tune instrument detection feasible in educational, rehearsal, and production settings. For that, we need a model that can generalize well across diverse instrument types. And this early performance benchmark gives us the reference we need to quantify how much value transfer learning adds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9daec5a",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856561a",
   "metadata": {},
   "source": [
    "Once we had the CNN-based baseline in place, we moved to another classical architecture in deep learning: the Multilayer Perceptron (MLP). The idea was simple—what if we strip away the convolutional structure and let dense layers directly interpret the audio feature vectors?\n",
    "\n",
    "Our features were already well-engineered: mean-compressed mel-spectrograms of shape (64,) per audio sample. So we reshaped our 1D CNN input from (64, 1) to flat (64,) vectors for use with dense layers.\n",
    "\n",
    "Why We Tried MLP in This Research: From a research perspective, trying a pure MLP served three purposes in our pipeline:\n",
    "\n",
    "- Baseline Benchmarking: We wanted to compare how a non-convolutional model performs on our features versus a 1D CNN. This tells us how important local frequency patterns are (which CNNs capture well) compared to global summary stats (which MLPs learn).\n",
    "\n",
    "- Model Simplicity: MLPs are faster to train and easy to interpret. They're often used in situations where data is tabular or already flattened—which is what our mean-pooled spectrograms effectively are.\n",
    "\n",
    "- Embedding Transfer Compatibility: Since our future transfer learning with VGGish will yield high-dimensional embeddings, we wanted to establish an MLP pipeline that can easily scale to 128–1024 dimensional VGGish features later in the research.\n",
    "\n",
    "The Model Architecture Explained: Here's how the MLP model was structured\n",
    "- Input Layer: Receives the 64-dim mel-spectrogram vector per audio snippet.\n",
    "\n",
    "- Dense Blocks: The architecture is progressively compressive: 1024 → 512 → 256 → 128. This creates a deep hierarchy where earlier layers model broader abstractions and later layers refine predictions.\n",
    "\n",
    "- Batch Normalization: Used after each dense layer to stabilize training and reduce internal covariate shift.\n",
    "\n",
    "- Dropout: Regularization is crucial here to prevent overfitting, especially given the limited number of samples in some instrument classes.\n",
    "\n",
    "- Output Layer: A softmax activation over the total number of out-of-tune labels.\n",
    "\n",
    "We used the Adam optimizer with a learning rate of 1e-4, which is conservative and often ideal for deep MLPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c9bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MLP MODEL FOR AUDIO FEATURES =====\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12101ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input for MLP: (N, 64, 1) → (N, 64)\n",
    "X_train_mlp = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_mlp = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Clear previous session\n",
    "K.clear_session()\n",
    "\n",
    "mlp_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f565e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m66,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m1,548\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">764,300</span> (2.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m764,300\u001b[0m (2.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">760,716</span> (2.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m760,716\u001b[0m (2.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> (14.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,584\u001b[0m (14.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== INPUT LAYER =====\n",
    "mlp_model.add(Input(shape=(64,)))\n",
    "\n",
    "# ===== DEEP FULLY CONNECTED BLOCKS =====\n",
    "mlp_model.add(Dense(1024, activation='relu'))\n",
    "mlp_model.add(BatchNormalization())\n",
    "mlp_model.add(Dropout(0.5))\n",
    "\n",
    "mlp_model.add(Dense(512, activation='relu'))\n",
    "mlp_model.add(BatchNormalization())\n",
    "mlp_model.add(Dropout(0.4))\n",
    "\n",
    "mlp_model.add(Dense(256, activation='relu'))\n",
    "mlp_model.add(BatchNormalization())\n",
    "mlp_model.add(Dropout(0.3))\n",
    "\n",
    "mlp_model.add(Dense(128, activation='relu'))\n",
    "mlp_model.add(Dropout(0.2))\n",
    "\n",
    "# ===== OUTPUT LAYER =====\n",
    "mlp_model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# ===== COMPILE =====\n",
    "mlp_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e9a26",
   "metadata": {},
   "source": [
    "Callbacks are like automated training assistants that monitor the model’s performance and take actions during training to make it more stable and efficient. Here’s what we used:\n",
    "\n",
    "EarlyStopping\n",
    "- Goal: Prevent the model from overfitting.\n",
    "\n",
    "- What it does: Monitors the validation loss (val_loss). If it doesn’t improve for 5 consecutive epochs, training is halted early.\n",
    "\n",
    "- restore_best_weights=True: Ensures the model reverts to the best checkpoint (lowest val_loss) before it started to overfit.\n",
    "\n",
    "- This is super helpful in our context since we have many instrument classes and some of them are underrepresented—so overfitting is a big risk.\n",
    "\n",
    "ReduceLROnPlateau\n",
    "- Goal: Dynamically adjust learning rate if the model gets stuck.\n",
    "\n",
    "- What it does: If val_loss stagnates for 2 epochs, it reduces the learning rate by 20% (i.e., multiplies it by 0.2).\n",
    "\n",
    "- Helps the model make finer adjustments once the loss plateaus, improving convergence and potentially getting past local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a778b",
   "metadata": {},
   "source": [
    "Here’s what’s happening in this line:\n",
    "\n",
    "Training data: X_train_mlp and y_train are fed into the MLP.\n",
    "\n",
    "Validation data: Used to monitor performance and trigger callbacks.\n",
    "\n",
    "Epochs: We set a max of 30, but EarlyStopping might end it earlier.\n",
    "\n",
    "Batch size: 32 is a balanced choice—big enough for performance, small enough to maintain gradient stability.\n",
    "\n",
    "Callbacks: Tells the training loop when to stop, and when to adapt.\n",
    "\n",
    "---\n",
    "\n",
    "Why This Was Critical for Our Research\n",
    "In our out-of-tune detection research, we deal with:\n",
    "\n",
    "A high number of classes (instruments),\n",
    "\n",
    "Imbalanced samples, and\n",
    "\n",
    "Dense feature vectors (from mel-spectrogram means).\n",
    "\n",
    "---\n",
    "\n",
    "This makes training delicate—overfitting and vanishing gradients are both real threats. Our callback setup provided guardrails to:\n",
    "\n",
    "Avoid overtraining on dominant classes,\n",
    "\n",
    "Fine-tune the learning rate when progress slowed,\n",
    "\n",
    "And save training time by stopping early if the model had peaked.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "417b3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.1729 - loss: 2.5653 - val_accuracy: 0.2911 - val_loss: 2.0556 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.2491 - loss: 2.1671 - val_accuracy: 0.3069 - val_loss: 1.9874 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.2772 - loss: 2.0818 - val_accuracy: 0.3209 - val_loss: 1.9342 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.2895 - loss: 2.0387 - val_accuracy: 0.3281 - val_loss: 1.9002 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.2979 - loss: 2.0070 - val_accuracy: 0.3316 - val_loss: 1.8833 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3027 - loss: 1.9876 - val_accuracy: 0.3327 - val_loss: 1.8620 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3085 - loss: 1.9706 - val_accuracy: 0.3385 - val_loss: 1.8423 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.3100 - loss: 1.9619 - val_accuracy: 0.3418 - val_loss: 1.8334 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3116 - loss: 1.9534 - val_accuracy: 0.3421 - val_loss: 1.8340 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3142 - loss: 1.9449 - val_accuracy: 0.3467 - val_loss: 1.8219 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3186 - loss: 1.9395 - val_accuracy: 0.3480 - val_loss: 1.8197 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3183 - loss: 1.9295 - val_accuracy: 0.3505 - val_loss: 1.8080 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3196 - loss: 1.9302 - val_accuracy: 0.3552 - val_loss: 1.7915 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3215 - loss: 1.9231 - val_accuracy: 0.3541 - val_loss: 1.7939 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3258 - loss: 1.9189 - val_accuracy: 0.3559 - val_loss: 1.7820 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3229 - loss: 1.9198 - val_accuracy: 0.3574 - val_loss: 1.7850 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m6293/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3247 - loss: 1.9176\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3247 - loss: 1.9176 - val_accuracy: 0.3558 - val_loss: 1.7898 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3278 - loss: 1.9073 - val_accuracy: 0.3655 - val_loss: 1.7628 - learning_rate: 2.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3284 - loss: 1.9034 - val_accuracy: 0.3674 - val_loss: 1.7588 - learning_rate: 2.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3285 - loss: 1.8965 - val_accuracy: 0.3679 - val_loss: 1.7588 - learning_rate: 2.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3290 - loss: 1.9010 - val_accuracy: 0.3681 - val_loss: 1.7535 - learning_rate: 2.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3311 - loss: 1.8916 - val_accuracy: 0.3693 - val_loss: 1.7532 - learning_rate: 2.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3306 - loss: 1.8944 - val_accuracy: 0.3695 - val_loss: 1.7522 - learning_rate: 2.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3308 - loss: 1.8908 - val_accuracy: 0.3708 - val_loss: 1.7509 - learning_rate: 2.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3308 - loss: 1.8921 - val_accuracy: 0.3701 - val_loss: 1.7487 - learning_rate: 2.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.3342 - loss: 1.8894 - val_accuracy: 0.3712 - val_loss: 1.7485 - learning_rate: 2.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.3336 - loss: 1.8909 - val_accuracy: 0.3714 - val_loss: 1.7448 - learning_rate: 2.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - accuracy: 0.3327 - loss: 1.8871 - val_accuracy: 0.3734 - val_loss: 1.7440 - learning_rate: 2.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.3315 - loss: 1.8841 - val_accuracy: 0.3739 - val_loss: 1.7436 - learning_rate: 2.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m6295/6295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - accuracy: 0.3328 - loss: 1.8836 - val_accuracy: 0.3744 - val_loss: 1.7400 - learning_rate: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# ===== CALLBACKS =====\n",
    "mlp_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2, verbose=1)\n",
    "]\n",
    "\n",
    "# ===== TRAIN MLP MODEL =====\n",
    "mlp_history = mlp_model.fit(\n",
    "    X_train_mlp, y_train,\n",
    "    validation_data=(X_test_mlp, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=mlp_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4397732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1574/1574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.41      5355\n",
      "           1       0.39      0.15      0.21      3715\n",
      "           2       0.58      0.01      0.02      2701\n",
      "           3       0.33      0.39      0.35      2830\n",
      "           4       0.44      0.67      0.53      5357\n",
      "           5       0.36      0.59      0.45      5364\n",
      "           6       0.36      0.18      0.24      5402\n",
      "           7       0.39      0.15      0.21      3688\n",
      "           8       0.36      0.66      0.46      5332\n",
      "           9       0.40      0.26      0.32      2232\n",
      "          10       0.34      0.37      0.36      5345\n",
      "          11       0.33      0.14      0.20      3033\n",
      "\n",
      "    accuracy                           0.37     50354\n",
      "   macro avg       0.39      0.33      0.31     50354\n",
      "weighted avg       0.38      0.37      0.34     50354\n",
      "\n",
      "\n",
      "MLP Confusion Matrix:\n",
      " [[2364   60    0  238  602  702   79   76  787  117  253   77]\n",
      " [ 441  548    0  226  451  514  268  185  528  106  333  115]\n",
      " [ 284   86   21  156  271  361  217   81  412   77  659   76]\n",
      " [ 213   37    0 1090  218  374  102   34  436   83  159   84]\n",
      " [ 156   30    0  141 3593  373   98   33  659   15  242   17]\n",
      " [ 293   37    0  172  520 3164  180   27  618   41  284   28]\n",
      " [ 655  175   11  306  523  654  966  156  765   92  934  165]\n",
      " [ 459  153    0  223  383  599  107  538  626  124  359  117]\n",
      " [ 144   35    0  128  588  597   71   18 3544    4  187   16]\n",
      " [ 238   35    0  116  263  454   44   15  326  589  124   28]\n",
      " [ 492  142    4  279  492  521  361  115  658  131 2002  148]\n",
      " [ 308   63    0  257  301  402  174   85  565  107  339  432]]\n"
     ]
    }
   ],
   "source": [
    "# ===== EVALUATION =====\n",
    "y_pred_probs_mlp = mlp_model.predict(X_test_mlp)\n",
    "y_pred_mlp = np.argmax(y_pred_probs_mlp, axis=1)\n",
    "y_true_mlp = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nMLP Classification Report:\\n\", classification_report(y_true_mlp, y_pred_mlp))\n",
    "print(\"\\nMLP Confusion Matrix:\\n\", confusion_matrix(y_true_mlp, y_pred_mlp))\n",
    "\n",
    "# ===== SAVE MLP MODEL =====\n",
    "mlp_model.save(\"mlp_out_of_tune_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70360f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== OPTIONAL: PLOT MLP TRAINING =====\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(mlp_history.history['accuracy'], label='Train Acc (MLP)')\n",
    "plt.plot(mlp_history.history['val_accuracy'], label='Val Acc (MLP)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('MLP Training Performance')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d721fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGGISH Backbone\n",
    "waveforms = np.stack([\n",
    "    librosa.util.fix_length(\n",
    "        librosa.load(fp, sr=SAMPLE_RATE, mono=True, duration=DURATION_SEC)[0],\n",
    "        size=int(SAMPLE_RATE * DURATION_SEC)\n",
    "    )\n",
    "    for fp in files_tl\n",
    "], axis=0).astype(np.float32)\n",
    "\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = os.path.expanduser(\"~/my_project/tfhub_cache\")\n",
    "print(\"Loading VGGish from TF-Hub…\")\n",
    "vggish_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/vggish/1\",\n",
    "    dtype=tf.float32,\n",
    "    trainable=False\n",
    ")\n",
    "inputs = tf.keras.Input(shape=(SAMPLE_RATE * int(DURATION_SEC),), dtype=tf.float32)\n",
    "patches = vggish_layer(inputs)                 # (None, T, 128)\n",
    "mean_embed = tf.reduce_mean(patches, axis=1)   # (None, 128)\n",
    "embed_model = tf.keras.Model(inputs, mean_embed)\n",
    "\n",
    "X_vgg = embed_model.predict(waveforms, batch_size=256, verbose=1)\n",
    "y_vgg = y[valid_indices].astype(np.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5174d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_tl = [filepaths[i] for i in valid_indices]\n",
    "ds = tf.data.Dataset.from_tensor_slices(files_tl)\n",
    "\n",
    "def load_and_pad(path):\n",
    "    # read file, decode WAV to float32 [samples,1]\n",
    "    wav, _ = tf.audio.decode_wav(tf.io.read_file(path),\n",
    "                                 desired_channels=1,\n",
    "                                 desired_samples=SAMPLE_RATE * int(DURATION_SEC))\n",
    "    wav = tf.squeeze(wav, axis=-1)                    # (samples,)\n",
    "    return wav\n",
    "\n",
    "ds = (\n",
    "    ds\n",
    "    .map(load_and_pad, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(256)          # tune this up or down to fit your GPU/CPU\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "821a2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_vggish(batch_waveforms):\n",
    "    # batch_waveforms: (batch_size, samples)\n",
    "    # tf.map_fn will call vggish(x) for each x in the batch\n",
    "    patches = tf.map_fn(lambda x: vggish(x), batch_waveforms,\n",
    "                        fn_output_signature=tf.float32)\n",
    "    # patches: (batch_size, T, 128)\n",
    "    return tf.reduce_mean(patches, axis=1)\n",
    "\n",
    "embeds = []\n",
    "for batch_wavs in ds:                  # ds yields (batch_size, samples)\n",
    "    mean_emb = batched_vggish(batch_wavs)\n",
    "    embeds.append(mean_emb)\n",
    "\n",
    "X_vgg = tf.concat(embeds, axis=0).numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fec82ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing VGGish embeddings…\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing VGGish embeddings…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m X_vgg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([extract_vggish(fp) \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m files_tl], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (N_valid,128)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m y_vgg \u001b[38;5;241m=\u001b[39m y[valid_indices]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[1;32mIn[37], line 16\u001b[0m, in \u001b[0;36mextract_vggish\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m<\u001b[39m SAMPLE_RATE \u001b[38;5;241m*\u001b[39m DURATION_SEC:\n\u001b[0;32m     15\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(y, (\u001b[38;5;241m0\u001b[39m, SAMPLE_RATE \u001b[38;5;241m*\u001b[39m DURATION_SEC \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)))\n\u001b[1;32m---> 16\u001b[0m patches \u001b[38;5;241m=\u001b[39m vggish(y)                         \u001b[38;5;66;03m# returns shape (T,128)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m mean_emb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(patches, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# ← NEW: mean-pool the time dimension\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_emb\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:1142\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1141\u001b[0m ):\n\u001b[1;32m-> 1142\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:242\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument:\n\u001b[1;32m--> 242\u001b[0m   result \u001b[38;5;241m=\u001b[39m f()\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:817\u001b[0m, in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 817\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1689\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1690\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1691\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1692\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1693\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1694\u001b[0m   )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Computing VGGish embeddings…\")\n",
    "X_vgg = np.stack([extract_vggish(fp) for fp in files_tl], axis=0)  # (N_valid,128)\n",
    "y_vgg = y[valid_indices].astype(np.float32) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaeec3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Train/test split\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_vgg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([extract_vggish(fp) \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m files_tl], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (N_valid,128)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m y_vgg \u001b[38;5;241m=\u001b[39m y[valid_indices]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \n\u001b[0;32m      5\u001b[0m Xv_train, Xv_test, yv_train, yv_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      6\u001b[0m     X_vgg, y_vgg,\n\u001b[0;32m      7\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m      8\u001b[0m     stratify\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(y_vgg, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      9\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m, in \u001b[0;36mextract_vggish\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_vggish\u001b[39m(path):\n\u001b[1;32m----> 2\u001b[0m     y, _ \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(path, sr\u001b[38;5;241m=\u001b[39mSAMPLE_RATE, mono\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, duration\u001b[38;5;241m=\u001b[39mDURATION_SEC)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m<\u001b[39m SAMPLE_RATE \u001b[38;5;241m*\u001b[39m DURATION_SEC:\n\u001b[0;32m      4\u001b[0m         y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(y, (\u001b[38;5;241m0\u001b[39m, SAMPLE_RATE \u001b[38;5;241m*\u001b[39m DURATION_SEC \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)))\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:190\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Final cleanup for dtype and contiguity\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mono:\n\u001b[1;32m--> 190\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     y \u001b[38;5;241m=\u001b[39m resample(y, orig_sr\u001b[38;5;241m=\u001b[39msr_native, target_sr\u001b[38;5;241m=\u001b[39msr, res_type\u001b[38;5;241m=\u001b[39mres_type)\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:505\u001b[0m, in \u001b[0;36mto_mono\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert an audio signal to mono by averaging samples across channels.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m(117601,)\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Validate the buffer\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m util\u001b[38;5;241m.\u001b[39mvalid_audio(y)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    508\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\librosa\\util\\utils.py:297\u001b[0m, in \u001b[0;36mvalid_audio\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio data must be at least one-dimensional, given y.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m     )\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(y)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio buffer is not finite everywhere\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:64\u001b[0m, in \u001b[0;36m_all\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train/test split\n",
    "Xv_train, Xv_test, yv_train, yv_test = train_test_split(\n",
    "    X_vgg, y_vgg,\n",
    "    test_size=0.2,\n",
    "    stratify=np.argmax(y_vgg, axis=1),\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb933cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dtype='string' is not a valid dtype for Keras type promotion.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m Xv_te_c \u001b[38;5;241m=\u001b[39m Xv_test[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,  np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m     20\u001b[0m cnn_tl \u001b[38;5;241m=\u001b[39m make_cnn1d_vgg(\u001b[38;5;241m128\u001b[39m, y_vgg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m hist_cnn_tl \u001b[38;5;241m=\u001b[39m cnn_tl\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     22\u001b[0m     Xv_tr_c, yv_train,\n\u001b[0;32m     23\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(Xv_te_c, yv_test),\n\u001b[0;32m     24\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     25\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     26\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     27\u001b[0m         EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     28\u001b[0m         ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m     ]\n\u001b[0;32m     30\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mmthe\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py:151\u001b[0m, in \u001b[0;36m_least_upper_bound\u001b[1;34m(*nodes)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    150\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m N \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m UB)\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m is not a valid dtype for Keras type promotion.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    154\u001b[0m CUB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;241m*\u001b[39mbounds)\n\u001b[0;32m    155\u001b[0m LUB \u001b[38;5;241m=\u001b[39m (CUB \u001b[38;5;241m&\u001b[39m N) \u001b[38;5;129;01mor\u001b[39;00m {c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m CUB \u001b[38;5;28;01mif\u001b[39;00m CUB\u001b[38;5;241m.\u001b[39missubset(UB[c])}\n",
      "\u001b[1;31mValueError\u001b[0m: dtype='string' is not a valid dtype for Keras type promotion."
     ]
    }
   ],
   "source": [
    "#1D CNN with VGGISH\n",
    "def make_cnn1d_vgg(input_dim, n_classes):\n",
    "    inp = tf.keras.Input(shape=(input_dim,1))\n",
    "    x = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(n_classes, activation=\"softmax\")(x)\n",
    "    m = Model(inp, out, name=\"cnn1d_vggish\")\n",
    "    m.compile(Adam(1e-4), \"categorical_crossentropy\", [\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "# reshape embeddings for Conv1D\n",
    "Xv_tr_c = Xv_train[..., np.newaxis]\n",
    "Xv_te_c = Xv_test[...,  np.newaxis]\n",
    "\n",
    "cnn_tl = make_cnn1d_vgg(128, y_vgg.shape[1])\n",
    "hist_cnn_tl = cnn_tl.fit(\n",
    "    Xv_tr_c, yv_train,\n",
    "    validation_data=(Xv_te_c, yv_test),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.2, verbose=1)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e43caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP on VGGish\n",
    "def make_mlp_vgg(input_dim, n_classes):\n",
    "    inp = tf.keras.Input(shape=(input_dim,))\n",
    "    x = Dense(256, activation=\"relu\")(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(n_classes, activation=\"softmax\")(x)\n",
    "    m = Model(inp, out, name=\"mlp_vggish\")\n",
    "    m.compile(Adam(1e-4), \"categorical_crossentropy\", [\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "mlp_tl = make_mlp_vgg(128, y_vgg.shape[1])\n",
    "hist_mlp_tl = mlp_tl.fit(\n",
    "    Xv_train, yv_train,\n",
    "    validation_data=(Xv_test, yv_test),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.2, verbose=1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Both Transfer Learning Models\n",
    "def report_tl(model, X, y, title):\n",
    "    y_pred = np.argmax(model.predict(X), axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title(f\"{title} Confusion Matrix\")\n",
    "    plt.xticks(rotation=45); plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "report_tl(mlp_tl, Xv_test,      yv_test, \"MLP + VGGish (TL)\")\n",
    "report_tl(cnn_tl, Xv_te_c,      yv_test, \"1D-CNN + VGGish (TL)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(history.history['val_accuracy'],   'k--', label='CNN scratch')\n",
    "plt.plot(mlp_history.history['val_accuracy'],'k:', label='MLP scratch')\n",
    "plt.plot(hist_mlp_tl.history['val_accuracy'],'b-', label='MLP + VGGish')\n",
    "plt.plot(hist_cnn_tl.history['val_accuracy'],'r-', label='CNN + VGGish')\n",
    "plt.title(\"Val Accuracy: Scratch vs. Transfer-Learned\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
    "plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
